{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flaml",
      "provenance": [],
      "authorship_tag": "ABX9TyMmxJx1pK9/HRuG0GtjFr/V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swarnava-96/FLAML/blob/main/flaml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E5O5GCWxFdG"
      },
      "source": [
        "# **FLAML - Fast, Lightweight and Economic AutoML**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq_qnJyYxF0o",
        "outputId": "ba82db60-ba6f-42d2-d653-5b580d2bc49c"
      },
      "source": [
        "!pip install flaml"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flaml\n",
            "  Downloading FLAML-0.6.5-py3-none-any.whl (156 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 21.5 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 20 kB 26.2 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 30 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 40 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 71 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 81 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 92 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 156 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.4.1)\n",
            "Requirement already satisfied: NumPy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.19.5)\n",
            "Requirement already satisfied: xgboost<=1.3.3,>=0.90 in /usr/local/lib/python3.7/dist-packages (from flaml) (0.90)\n",
            "Collecting lightgbm>=2.3.1\n",
            "  Downloading lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 53.7 MB/s \n",
            "\u001b[?25hCollecting scikit-learn>=0.24\n",
            "  Downloading scikit_learn-1.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.1 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting catboost>=0.23\n",
            "  Downloading catboost-1.0.0-cp37-none-manylinux1_x86_64.whl (76.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.4 MB 52 kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml) (3.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml) (4.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml) (1.1.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml) (1.15.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->flaml) (0.37.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost>=0.23->flaml) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost>=0.23->flaml) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml) (1.0.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost>=0.23->flaml) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost>=0.23->flaml) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost>=0.23->flaml) (0.10.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost>=0.23->flaml) (1.3.3)\n",
            "Installing collected packages: threadpoolctl, scikit-learn, lightgbm, catboost, flaml\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed catboost-1.0.0 flaml-0.6.5 lightgbm-3.2.1 scikit-learn-1.0 threadpoolctl-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp76lPNhxRFV"
      },
      "source": [
        "## Classification on IRIS Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZsTPKUKxHyV",
        "outputId": "93d133c2-66f2-4826-c1b4-1913d58ad0df"
      },
      "source": [
        "from flaml import AutoML\n",
        "from sklearn.datasets import load_iris\n",
        "# Initializing the AutoML instance\n",
        "automl = AutoML()\n",
        "# Goal setting and constraint\n",
        "automl_settings = {\n",
        "    \"time_budget\" : 10, # in seconds\n",
        "    \"metric\" : \"accuracy\",\n",
        "    \"task\" : \"classification\",\n",
        "    \"log_file_name\" : 'iris.log',\n",
        "}\n",
        "X_train, y_train = load_iris(return_X_y = True)\n",
        "# Train with labeled input data\n",
        "automl.fit(X_train = X_train, y_train = y_train, **automl_settings)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 10-02 06:58:43] {1432} INFO - Evaluation method: cv\n",
            "[flaml.automl: 10-02 06:58:43] {1478} INFO - Minimizing error metric: 1-accuracy\n",
            "[flaml.automl: 10-02 06:58:43] {1515} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'lrl1']\n",
            "[flaml.automl: 10-02 06:58:43] {1748} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:43] {1866} INFO - Estimated sufficient time budget=524s. Estimated necessary time budget=10s.\n",
            "[flaml.automl: 10-02 06:58:43] {1944} INFO -  at 0.1s,\testimator lgbm's best error=0.0733,\tbest estimator lgbm's best error=0.0733\n",
            "[flaml.automl: 10-02 06:58:43] {1748} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:43] {1944} INFO -  at 0.1s,\testimator lgbm's best error=0.0733,\tbest estimator lgbm's best error=0.0733\n",
            "[flaml.automl: 10-02 06:58:43] {1748} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:43] {1944} INFO -  at 0.2s,\testimator lgbm's best error=0.0533,\tbest estimator lgbm's best error=0.0533\n",
            "[flaml.automl: 10-02 06:58:43] {1748} INFO - iteration 3, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:43] {1944} INFO -  at 0.2s,\testimator lgbm's best error=0.0533,\tbest estimator lgbm's best error=0.0533\n",
            "[flaml.automl: 10-02 06:58:43] {1748} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:43] {1944} INFO -  at 0.3s,\testimator lgbm's best error=0.0533,\tbest estimator lgbm's best error=0.0533\n",
            "[flaml.automl: 10-02 06:58:43] {1748} INFO - iteration 5, current learner xgboost\n",
            "[flaml.automl: 10-02 06:58:43] {1944} INFO -  at 0.5s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0533\n",
            "[flaml.automl: 10-02 06:58:43] {1748} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:43] {1944} INFO -  at 0.5s,\testimator lgbm's best error=0.0467,\tbest estimator lgbm's best error=0.0467\n",
            "[flaml.automl: 10-02 06:58:43] {1748} INFO - iteration 7, current learner extra_tree\n",
            "[flaml.automl: 10-02 06:58:44] {1944} INFO -  at 1.6s,\testimator extra_tree's best error=0.0533,\tbest estimator lgbm's best error=0.0467\n",
            "[flaml.automl: 10-02 06:58:44] {1748} INFO - iteration 8, current learner rf\n",
            "[flaml.automl: 10-02 06:58:46] {1944} INFO -  at 2.8s,\testimator rf's best error=0.0467,\tbest estimator lgbm's best error=0.0467\n",
            "[flaml.automl: 10-02 06:58:46] {1748} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:46] {1944} INFO -  at 2.8s,\testimator lgbm's best error=0.0467,\tbest estimator lgbm's best error=0.0467\n",
            "[flaml.automl: 10-02 06:58:46] {1748} INFO - iteration 10, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:46] {1944} INFO -  at 2.9s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:46] {1748} INFO - iteration 11, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:46] {1944} INFO -  at 2.9s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:46] {1748} INFO - iteration 12, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:46] {1944} INFO -  at 2.9s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:46] {1748} INFO - iteration 13, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:46] {1944} INFO -  at 3.0s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:46] {1748} INFO - iteration 14, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:46] {1944} INFO -  at 3.0s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:46] {1748} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl: 10-02 06:58:46] {1944} INFO -  at 3.1s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:46] {1748} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:46] {1944} INFO -  at 3.1s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:46] {1748} INFO - iteration 17, current learner xgboost\n",
            "[flaml.automl: 10-02 06:58:46] {1944} INFO -  at 3.1s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:46] {1748} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:46] {1944} INFO -  at 3.2s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:46] {1748} INFO - iteration 19, current learner xgboost\n",
            "[flaml.automl: 10-02 06:58:46] {1944} INFO -  at 3.2s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:46] {1748} INFO - iteration 20, current learner rf\n",
            "[flaml.automl: 10-02 06:58:47] {1944} INFO -  at 4.4s,\testimator rf's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:47] {1748} INFO - iteration 21, current learner xgboost\n",
            "[flaml.automl: 10-02 06:58:47] {1944} INFO -  at 4.4s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:47] {1748} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:47] {1944} INFO -  at 4.4s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:47] {1748} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:47] {1944} INFO -  at 4.5s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:47] {1748} INFO - iteration 24, current learner xgboost\n",
            "[flaml.automl: 10-02 06:58:47] {1944} INFO -  at 4.5s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:47] {1748} INFO - iteration 25, current learner extra_tree\n",
            "[flaml.automl: 10-02 06:58:48] {1944} INFO -  at 5.7s,\testimator extra_tree's best error=0.0533,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:48] {1748} INFO - iteration 26, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:48] {1944} INFO -  at 5.7s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:48] {1748} INFO - iteration 27, current learner xgboost\n",
            "[flaml.automl: 10-02 06:58:48] {1944} INFO -  at 5.8s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:48] {1748} INFO - iteration 28, current learner xgboost\n",
            "[flaml.automl: 10-02 06:58:49] {1944} INFO -  at 5.8s,\testimator xgboost's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:49] {1748} INFO - iteration 29, current learner xgboost\n",
            "[flaml.automl: 10-02 06:58:49] {1944} INFO -  at 5.8s,\testimator xgboost's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:49] {1748} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:49] {1944} INFO -  at 5.9s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:49] {1748} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:49] {1944} INFO -  at 5.9s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:49] {1748} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:49] {1944} INFO -  at 6.0s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:49] {1748} INFO - iteration 33, current learner xgboost\n",
            "[flaml.automl: 10-02 06:58:49] {1944} INFO -  at 6.0s,\testimator xgboost's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:49] {1748} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:49] {1944} INFO -  at 6.0s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
            "[flaml.automl: 10-02 06:58:49] {1748} INFO - iteration 35, current learner rf\n",
            "[flaml.automl: 10-02 06:58:50] {1944} INFO -  at 7.3s,\testimator rf's best error=0.0267,\tbest estimator rf's best error=0.0267\n",
            "[flaml.automl: 10-02 06:58:50] {1748} INFO - iteration 36, current learner catboost\n",
            "[flaml.automl: 10-02 06:58:50] {1944} INFO -  at 7.8s,\testimator catboost's best error=0.0467,\tbest estimator rf's best error=0.0267\n",
            "[flaml.automl: 10-02 06:58:50] {1748} INFO - iteration 37, current learner extra_tree\n",
            "[flaml.automl: 10-02 06:58:52] {1944} INFO -  at 9.0s,\testimator extra_tree's best error=0.0267,\tbest estimator rf's best error=0.0267\n",
            "[flaml.automl: 10-02 06:58:52] {1748} INFO - iteration 38, current learner catboost\n",
            "[flaml.automl: 10-02 06:58:52] {1944} INFO -  at 9.3s,\testimator catboost's best error=0.0400,\tbest estimator rf's best error=0.0267\n",
            "[flaml.automl: 10-02 06:58:52] {1748} INFO - iteration 39, current learner xgboost\n",
            "[flaml.automl: 10-02 06:58:52] {1944} INFO -  at 9.3s,\testimator xgboost's best error=0.0467,\tbest estimator rf's best error=0.0267\n",
            "[flaml.automl: 10-02 06:58:52] {1748} INFO - iteration 40, current learner catboost\n",
            "[flaml.automl: 10-02 06:58:52] {1944} INFO -  at 9.5s,\testimator catboost's best error=0.0333,\tbest estimator rf's best error=0.0267\n",
            "[flaml.automl: 10-02 06:58:52] {1748} INFO - iteration 41, current learner catboost\n",
            "[flaml.automl: 10-02 06:58:52] {1944} INFO -  at 9.7s,\testimator catboost's best error=0.0333,\tbest estimator rf's best error=0.0267\n",
            "[flaml.automl: 10-02 06:58:52] {1748} INFO - iteration 42, current learner xgboost\n",
            "[flaml.automl: 10-02 06:58:52] {1944} INFO -  at 9.8s,\testimator xgboost's best error=0.0467,\tbest estimator rf's best error=0.0267\n",
            "[flaml.automl: 10-02 06:58:52] {1748} INFO - iteration 43, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:52] {1944} INFO -  at 9.8s,\testimator lgbm's best error=0.0400,\tbest estimator rf's best error=0.0267\n",
            "[flaml.automl: 10-02 06:58:52] {1748} INFO - iteration 44, current learner xgboost\n",
            "[flaml.automl: 10-02 06:58:53] {1944} INFO -  at 9.8s,\testimator xgboost's best error=0.0467,\tbest estimator rf's best error=0.0267\n",
            "[flaml.automl: 10-02 06:58:53] {1748} INFO - iteration 45, current learner xgboost\n",
            "[flaml.automl: 10-02 06:58:53] {1944} INFO -  at 9.9s,\testimator xgboost's best error=0.0467,\tbest estimator rf's best error=0.0267\n",
            "[flaml.automl: 10-02 06:58:53] {1748} INFO - iteration 46, current learner xgboost\n",
            "[flaml.automl: 10-02 06:58:53] {1944} INFO -  at 9.9s,\testimator xgboost's best error=0.0467,\tbest estimator rf's best error=0.0267\n",
            "[flaml.automl: 10-02 06:58:53] {1748} INFO - iteration 47, current learner lgbm\n",
            "[flaml.automl: 10-02 06:58:53] {1944} INFO -  at 9.9s,\testimator lgbm's best error=0.0400,\tbest estimator rf's best error=0.0267\n",
            "[flaml.automl: 10-02 06:58:53] {1748} INFO - iteration 48, current learner xgboost\n",
            "[flaml.automl: 10-02 06:58:53] {1944} INFO -  at 10.0s,\testimator xgboost's best error=0.0467,\tbest estimator rf's best error=0.0267\n",
            "[flaml.automl: 10-02 06:58:53] {1748} INFO - iteration 49, current learner lrl1\n",
            "No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "[flaml.automl: 10-02 06:58:53] {1944} INFO -  at 10.1s,\testimator lrl1's best error=0.0667,\tbest estimator rf's best error=0.0267\n",
            "[flaml.automl: 10-02 06:58:53] {2043} INFO - selected model: RandomForestClassifier(max_features=0.6594076331625844, max_leaf_nodes=4,\n",
            "                       n_estimators=5, n_jobs=-1)\n",
            "[flaml.automl: 10-02 06:58:53] {2106} INFO - retrain rf for 0.3s\n",
            "[flaml.automl: 10-02 06:58:53] {2110} INFO - retrained model: RandomForestClassifier(max_features=0.6594076331625844, max_leaf_nodes=4,\n",
            "                       n_estimators=5, n_jobs=-1)\n",
            "[flaml.automl: 10-02 06:58:53] {1539} INFO - fit succeeded\n",
            "[flaml.automl: 10-02 06:58:53] {1541} INFO - Time taken to find the best model: 7.3005757331848145\n",
            "[flaml.automl: 10-02 06:58:53] {1555} WARNING - Time taken to find the best model is 73% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlvY8vVvzD9g",
        "outputId": "b8c2bfaf-9b4f-4d1f-c681-ad38fd81cd3e"
      },
      "source": [
        "# Prediction\n",
        "print(automl.predict_proba(X_train))\n",
        "# Export the best model\n",
        "print(automl.model)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [0.82142857 0.16785714 0.01071429]\n",
            " [0.82142857 0.16785714 0.01071429]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [0.82142857 0.16785714 0.01071429]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [0.82142857 0.16785714 0.01071429]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [0.82142857 0.16785714 0.01071429]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [1.         0.         0.        ]\n",
            " [0.02142857 0.65713423 0.3214372 ]\n",
            " [0.02142857 0.65713423 0.3214372 ]\n",
            " [0.02142857 0.65713423 0.3214372 ]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.65713423 0.3214372 ]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.79357867 0.18499275]\n",
            " [0.         0.92047191 0.07952809]\n",
            " [0.02142857 0.65713423 0.3214372 ]\n",
            " [0.         0.92047191 0.07952809]\n",
            " [0.         0.92047191 0.07952809]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.65713423 0.3214372 ]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.53525763 0.4433138 ]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.79357867 0.18499275]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.65713423 0.3214372 ]\n",
            " [0.02142857 0.65713423 0.3214372 ]\n",
            " [0.02142857 0.65713423 0.3214372 ]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.         0.56462987 0.43537013]\n",
            " [0.         0.92047191 0.07952809]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.65713423 0.3214372 ]\n",
            " [0.02142857 0.79357867 0.18499275]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.         0.92047191 0.07952809]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.         0.92047191 0.07952809]\n",
            " [0.02142857 0.90832906 0.07024237]\n",
            " [0.         0.07645963 0.92354037]\n",
            " [0.         0.19155844 0.80844156]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.07645963 0.92354037]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.54740049 0.45259951]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.19155844 0.80844156]\n",
            " [0.         0.19155844 0.80844156]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.56462987 0.43537013]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.02142857 0.34989177 0.62867965]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.02142857 0.23479296 0.74377847]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.02142857 0.53525763 0.4433138 ]\n",
            " [0.02142857 0.34989177 0.62867965]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.30296756 0.69703244]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.63524534 0.36475466]\n",
            " [0.         0.36879654 0.63120346]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.07645963 0.92354037]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.02142857 0.53525763 0.4433138 ]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.19155844 0.80844156]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.07645963 0.92354037]\n",
            " [0.         0.12201518 0.87798482]\n",
            " [0.         0.19155844 0.80844156]\n",
            " [0.         0.19155844 0.80844156]]\n",
            "<flaml.model.RandomForestEstimator object at 0x7f30b1852bd0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWV4JQ2A0PLj"
      },
      "source": [
        "## Regression on Boston Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7goGTlhzr_j",
        "outputId": "9720b45b-1444-4c1c-a110-d51c74662bdc"
      },
      "source": [
        "from flaml import AutoML\n",
        "from sklearn.datasets import load_boston\n",
        "# Initialize an AutoML instance\n",
        "automl = AutoML()\n",
        "# Specify automl goal and constraint\n",
        "automl_settings = {\n",
        "    \"time_budget\" : 10, # in seconds\n",
        "    \"metric\" : \"r2\",\n",
        "    \"task\" : \"regression\",\n",
        "    \"log_file_name\" : \"boston.log\",\n",
        "}\n",
        "X_train, y_train = load_boston(return_X_y = True)\n",
        "# Train with labelled input data\n",
        "automl.fit(X_train = X_train, y_train = y_train, **automl_settings)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this case special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows:\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and:\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "[flaml.automl: 10-02 07:11:49] {1432} INFO - Evaluation method: cv\n",
            "[flaml.automl: 10-02 07:11:50] {1478} INFO - Minimizing error metric: 1-r2\n",
            "[flaml.automl: 10-02 07:11:50] {1515} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree']\n",
            "[flaml.automl: 10-02 07:11:50] {1748} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:50] {1866} INFO - Estimated sufficient time budget=266s. Estimated necessary time budget=1s.\n",
            "[flaml.automl: 10-02 07:11:50] {1944} INFO -  at 0.0s,\testimator lgbm's best error=0.6257,\tbest estimator lgbm's best error=0.6257\n",
            "[flaml.automl: 10-02 07:11:50] {1748} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:50] {1944} INFO -  at 0.1s,\testimator lgbm's best error=0.6257,\tbest estimator lgbm's best error=0.6257\n",
            "[flaml.automl: 10-02 07:11:50] {1748} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:50] {1944} INFO -  at 0.1s,\testimator lgbm's best error=0.3498,\tbest estimator lgbm's best error=0.3498\n",
            "[flaml.automl: 10-02 07:11:50] {1748} INFO - iteration 3, current learner xgboost\n",
            "[flaml.automl: 10-02 07:11:50] {1944} INFO -  at 0.1s,\testimator xgboost's best error=3.1963,\tbest estimator lgbm's best error=0.3498\n",
            "[flaml.automl: 10-02 07:11:50] {1748} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:50] {1944} INFO -  at 0.2s,\testimator lgbm's best error=0.2466,\tbest estimator lgbm's best error=0.2466\n",
            "[flaml.automl: 10-02 07:11:50] {1748} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:50] {1944} INFO -  at 0.2s,\testimator lgbm's best error=0.2466,\tbest estimator lgbm's best error=0.2466\n",
            "[flaml.automl: 10-02 07:11:50] {1748} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:50] {1944} INFO -  at 0.2s,\testimator lgbm's best error=0.2087,\tbest estimator lgbm's best error=0.2087\n",
            "[flaml.automl: 10-02 07:11:50] {1748} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:50] {1944} INFO -  at 0.3s,\testimator lgbm's best error=0.2087,\tbest estimator lgbm's best error=0.2087\n",
            "[flaml.automl: 10-02 07:11:50] {1748} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:50] {1944} INFO -  at 0.3s,\testimator lgbm's best error=0.2087,\tbest estimator lgbm's best error=0.2087\n",
            "[flaml.automl: 10-02 07:11:50] {1748} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:50] {1944} INFO -  at 0.3s,\testimator lgbm's best error=0.1682,\tbest estimator lgbm's best error=0.1682\n",
            "[flaml.automl: 10-02 07:11:50] {1748} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl: 10-02 07:11:50] {1944} INFO -  at 0.4s,\testimator xgboost's best error=3.1963,\tbest estimator lgbm's best error=0.1682\n",
            "[flaml.automl: 10-02 07:11:50] {1748} INFO - iteration 11, current learner extra_tree\n",
            "[flaml.automl: 10-02 07:11:51] {1944} INFO -  at 1.5s,\testimator extra_tree's best error=0.3453,\tbest estimator lgbm's best error=0.1682\n",
            "[flaml.automl: 10-02 07:11:51] {1748} INFO - iteration 12, current learner rf\n",
            "[flaml.automl: 10-02 07:11:52] {1944} INFO -  at 2.6s,\testimator rf's best error=0.3176,\tbest estimator lgbm's best error=0.1682\n",
            "[flaml.automl: 10-02 07:11:52] {1748} INFO - iteration 13, current learner xgboost\n",
            "[flaml.automl: 10-02 07:11:52] {1944} INFO -  at 2.7s,\testimator xgboost's best error=0.8624,\tbest estimator lgbm's best error=0.1682\n",
            "[flaml.automl: 10-02 07:11:52] {1748} INFO - iteration 14, current learner xgboost\n",
            "[flaml.automl: 10-02 07:11:52] {1944} INFO -  at 2.7s,\testimator xgboost's best error=0.3204,\tbest estimator lgbm's best error=0.1682\n",
            "[flaml.automl: 10-02 07:11:52] {1748} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl: 10-02 07:11:52] {1944} INFO -  at 2.7s,\testimator xgboost's best error=0.3204,\tbest estimator lgbm's best error=0.1682\n",
            "[flaml.automl: 10-02 07:11:52] {1748} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:52] {1944} INFO -  at 2.8s,\testimator lgbm's best error=0.1682,\tbest estimator lgbm's best error=0.1682\n",
            "[flaml.automl: 10-02 07:11:52] {1748} INFO - iteration 17, current learner xgboost\n",
            "[flaml.automl: 10-02 07:11:52] {1944} INFO -  at 2.8s,\testimator xgboost's best error=0.2500,\tbest estimator lgbm's best error=0.1682\n",
            "[flaml.automl: 10-02 07:11:52] {1748} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:52] {1944} INFO -  at 2.9s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:52] {1748} INFO - iteration 19, current learner xgboost\n",
            "[flaml.automl: 10-02 07:11:52] {1944} INFO -  at 2.9s,\testimator xgboost's best error=0.2500,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:52] {1748} INFO - iteration 20, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:52] {1944} INFO -  at 3.0s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:52] {1748} INFO - iteration 21, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:53] {1944} INFO -  at 3.0s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:53] {1748} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:53] {1944} INFO -  at 3.1s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:53] {1748} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:53] {1944} INFO -  at 3.2s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:53] {1748} INFO - iteration 24, current learner xgboost\n",
            "[flaml.automl: 10-02 07:11:53] {1944} INFO -  at 3.2s,\testimator xgboost's best error=0.2500,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:53] {1748} INFO - iteration 25, current learner extra_tree\n",
            "[flaml.automl: 10-02 07:11:54] {1944} INFO -  at 4.3s,\testimator extra_tree's best error=0.2470,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:54] {1748} INFO - iteration 26, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:54] {1944} INFO -  at 4.4s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:54] {1748} INFO - iteration 27, current learner xgboost\n",
            "[flaml.automl: 10-02 07:11:54] {1944} INFO -  at 4.4s,\testimator xgboost's best error=0.2500,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:54] {1748} INFO - iteration 28, current learner xgboost\n",
            "[flaml.automl: 10-02 07:11:54] {1944} INFO -  at 4.5s,\testimator xgboost's best error=0.2500,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:54] {1748} INFO - iteration 29, current learner xgboost\n",
            "[flaml.automl: 10-02 07:11:54] {1944} INFO -  at 4.5s,\testimator xgboost's best error=0.2500,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:54] {1748} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:54] {1944} INFO -  at 4.5s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:54] {1748} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:54] {1944} INFO -  at 4.6s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:54] {1748} INFO - iteration 32, current learner catboost\n",
            "[flaml.automl: 10-02 07:11:55] {1944} INFO -  at 5.6s,\testimator catboost's best error=0.1409,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:55] {1748} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:55] {1944} INFO -  at 5.7s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:55] {1748} INFO - iteration 34, current learner xgboost\n",
            "[flaml.automl: 10-02 07:11:55] {1944} INFO -  at 5.7s,\testimator xgboost's best error=0.2500,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:55] {1748} INFO - iteration 35, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:55] {1944} INFO -  at 5.8s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:55] {1748} INFO - iteration 36, current learner rf\n",
            "[flaml.automl: 10-02 07:11:56] {1944} INFO -  at 6.9s,\testimator rf's best error=0.2298,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:56] {1748} INFO - iteration 37, current learner extra_tree\n",
            "[flaml.automl: 10-02 07:11:58] {1944} INFO -  at 8.0s,\testimator extra_tree's best error=0.2470,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:58] {1748} INFO - iteration 38, current learner catboost\n",
            "[flaml.automl: 10-02 07:11:58] {1944} INFO -  at 8.5s,\testimator catboost's best error=0.1409,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:58] {1748} INFO - iteration 39, current learner xgboost\n",
            "[flaml.automl: 10-02 07:11:58] {1944} INFO -  at 8.5s,\testimator xgboost's best error=0.2492,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:58] {1748} INFO - iteration 40, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:58] {1944} INFO -  at 8.6s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:58] {1748} INFO - iteration 41, current learner catboost\n",
            "[flaml.automl: 10-02 07:11:58] {1944} INFO -  at 9.0s,\testimator catboost's best error=0.1409,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:59] {1748} INFO - iteration 42, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:59] {1944} INFO -  at 9.1s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:59] {1748} INFO - iteration 43, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:59] {1944} INFO -  at 9.1s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:59] {1748} INFO - iteration 44, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:59] {1944} INFO -  at 9.2s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:59] {1748} INFO - iteration 45, current learner xgboost\n",
            "[flaml.automl: 10-02 07:11:59] {1944} INFO -  at 9.2s,\testimator xgboost's best error=0.2492,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:59] {1748} INFO - iteration 46, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:59] {1944} INFO -  at 9.3s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:59] {1748} INFO - iteration 47, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:59] {1944} INFO -  at 9.4s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:59] {1748} INFO - iteration 48, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:59] {1944} INFO -  at 9.4s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:59] {1748} INFO - iteration 49, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:59] {1944} INFO -  at 9.5s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:59] {1748} INFO - iteration 50, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:59] {1944} INFO -  at 9.5s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:59] {1748} INFO - iteration 51, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:59] {1944} INFO -  at 9.6s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:59] {1748} INFO - iteration 52, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:59] {1944} INFO -  at 9.6s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:59] {1748} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:59] {1944} INFO -  at 9.7s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:59] {1748} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:59] {1944} INFO -  at 9.7s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:59] {1748} INFO - iteration 55, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:59] {1944} INFO -  at 9.8s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:59] {1748} INFO - iteration 56, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:59] {1944} INFO -  at 9.8s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:59] {1748} INFO - iteration 57, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:59] {1944} INFO -  at 9.8s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:59] {1748} INFO - iteration 58, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:59] {1944} INFO -  at 9.9s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:59] {1748} INFO - iteration 59, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:59] {1944} INFO -  at 9.9s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:59] {1748} INFO - iteration 60, current learner lgbm\n",
            "[flaml.automl: 10-02 07:11:59] {1944} INFO -  at 9.9s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:59] {1748} INFO - iteration 61, current learner xgboost\n",
            "[flaml.automl: 10-02 07:11:59] {1944} INFO -  at 10.0s,\testimator xgboost's best error=0.2492,\tbest estimator lgbm's best error=0.1356\n",
            "[flaml.automl: 10-02 07:11:59] {2043} INFO - selected model: LGBMRegressor(colsample_bytree=0.6649148062238498,\n",
            "              learning_rate=0.17402065726724145, max_bin=128,\n",
            "              min_child_samples=3, n_estimators=32, num_leaves=9,\n",
            "              objective='regression', reg_alpha=0.0009765625,\n",
            "              reg_lambda=0.006761362450996487, verbose=-1)\n",
            "[flaml.automl: 10-02 07:11:59] {2106} INFO - retrain lgbm for 0.0s\n",
            "[flaml.automl: 10-02 07:11:59] {2110} INFO - retrained model: LGBMRegressor(colsample_bytree=0.6649148062238498,\n",
            "              learning_rate=0.17402065726724145, max_bin=128,\n",
            "              min_child_samples=3, n_estimators=32, num_leaves=9,\n",
            "              objective='regression', reg_alpha=0.0009765625,\n",
            "              reg_lambda=0.006761362450996487, verbose=-1)\n",
            "[flaml.automl: 10-02 07:12:00] {1539} INFO - fit succeeded\n",
            "[flaml.automl: 10-02 07:12:00] {1541} INFO - Time taken to find the best model: 2.864903450012207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOx17l2j2EDL",
        "outputId": "29109a93-3d17-4dd2-efba-4c4d5a8eb4ee"
      },
      "source": [
        "# Prediction\n",
        "print(automl.predict(X_train))\n",
        "# Export the best model\n",
        "print(automl.model)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[25.85426879 22.17737651 33.79509964 33.47189557 35.61127167 26.6926382\n",
            " 21.53656446 20.99173684 16.18673463 18.75433976 18.20961633 20.48286627\n",
            " 20.20745331 19.5131759  18.82401423 19.81864373 21.91420674 17.53721008\n",
            " 18.69698259 19.07769813 14.3021372  18.32367106 16.63348583 15.34809335\n",
            " 16.27978499 15.13176242 16.94561436 15.20221211 18.67737191 20.75076542\n",
            " 13.88486622 17.70376242 13.89318927 14.90744983 14.32837615 21.02020963\n",
            " 20.89410764 21.52937191 23.19568492 30.3824402  34.45306735 29.43834549\n",
            " 24.62262048 24.62262048 22.21884844 20.87353145 20.36481607 18.09945043\n",
            " 15.55273032 18.67322033 20.4058421  21.53510487 24.1301244  21.73345138\n",
            " 17.74586736 34.48285914 23.17178682 31.55632404 23.26235097 20.39233374\n",
            " 18.98627393 17.89811291 22.71262836 25.23349363 32.76974079 25.04432847\n",
            " 19.83367435 20.94710592 19.92700235 21.23614492 23.62275307 21.08771163\n",
            " 22.31713619 23.46816704 24.39319272 22.93449232 21.05889974 21.25605159\n",
            " 21.17094097 21.4104049  26.32531539 24.84165632 23.41875466 22.8120377\n",
            " 23.12681643 26.07314549 21.34032521 22.59488629 26.81601064 30.10072674\n",
            " 23.47133879 22.62450376 23.40848205 25.20150116 20.74313622 26.63582822\n",
            " 22.56394496 40.98684448 43.03722064 33.01766391 24.84190574 25.43455857\n",
            " 18.18875737 20.49979008 20.57478854 18.13734457 17.91303198 20.49979008\n",
            " 20.57478854 18.8322359  21.11833105 22.96406162 18.57150096 18.83508569\n",
            " 20.89066811 18.58619509 20.95795201 20.4381487  18.58619509 20.72664127\n",
            " 21.62721157 21.09344795 19.51757484 17.53599996 19.51757484 19.78584094\n",
            " 17.36958717 16.39253423 16.86856532 15.853506   19.71749942 19.35197602\n",
            " 20.07005987 17.39965131 15.92640822 17.14455857 16.51379168 18.47224498\n",
            " 14.38445978 16.3202417  14.36742357 13.09473563 14.46737843 14.73422787\n",
            " 13.79400434 15.41208419 17.4578433  13.90794056 14.77126156 15.18245573\n",
            " 20.57464694 19.22984984 18.55647575 18.00616692 18.32648919 16.20917324\n",
            " 15.94048355 40.44304575 24.93995665 24.55706495 26.17126032 47.56299085\n",
            " 48.57509584 48.92296041 21.89045992 23.47663172 48.88830552 21.21745586\n",
            " 22.24469801 22.12855254 21.21745586 21.21745586 20.71319839 23.99651065\n",
            " 22.20628325 27.61661251 22.24779919 24.35641132 28.82910017 37.4336891\n",
            " 41.82612485 31.40530134 37.2617559  31.63960058 24.06803666 27.95722996\n",
            " 48.31846952 28.85327104 30.14916251 34.44402572 32.43461899 29.21282212\n",
            " 34.58982726 29.81477151 29.09606486 48.42621104 33.91839935 30.81677594\n",
            " 32.76161643 33.0058017  33.0058017  23.35364085 43.33574902 48.15111119\n",
            " 48.42621104 23.7319089  23.12852809 20.08360727 22.292716   18.3152002\n",
            " 20.15144641 18.32878493 21.24073814 25.61968555 20.32169665 23.99488849\n",
            " 22.29871705 25.40375278 20.33285354 23.37310689 27.79745637 20.83190671\n",
            " 26.36215877 26.63632325 45.15579507 45.69665731 43.92509937 30.92171422\n",
            " 45.71273114 31.55492563 22.4680608  32.11251767 44.32137075 45.54983148\n",
            " 27.42782572 22.9617272  25.92533441 32.46382356 23.75605744 25.56397894\n",
            " 24.60210386 20.62465265 21.53758885 25.22345796 19.06214513 17.84017293\n",
            " 21.69626278 20.93442255 22.86047593 26.53529504 23.71037189 26.40330856\n",
            " 32.45002858 40.12441971 21.62770163 20.16906432 43.22019612 48.96580343\n",
            " 36.19046627 31.35388466 34.9431359  44.12722649 46.8156711  32.19902229\n",
            " 34.9431359  22.86211519 29.53873565 47.98290935 46.00178483 21.93765745\n",
            " 21.54793337 25.23142491 24.33883673 35.61319402 31.31696508 32.04267127\n",
            " 33.35308931 31.2559175  25.95200717 34.35510039 46.48696004 35.2163881\n",
            " 45.64080794 49.0327787  30.55331866 22.33257136 21.69757503 23.53652066\n",
            " 23.08245711 24.79937913 31.21276685 34.29118996 28.11258611 23.85939846\n",
            " 21.98861298 27.07522156 25.03558428 19.24341933 24.20354062 30.25026064\n",
            " 26.3510736  24.97967893 24.33108926 32.31816475 34.95139768 27.72254529\n",
            " 34.27356754 28.58064288 26.28401898 20.25949225 19.15765455 23.40595016\n",
            " 19.9069318  22.22895448 23.43789368 19.7967241  17.99129269 18.86799165\n",
            " 21.90295702 21.44864267 23.74221793 23.74221793 21.77357441 19.88044313\n",
            " 23.74861493 26.188891   24.33547333 21.31173366 20.3949194  23.03935223\n",
            " 22.0186464  19.24261422 19.64398129 21.95831249 21.85754325 20.6350395\n",
            " 20.01568444 19.85894712 20.79851822 20.16200017 20.51536951 31.99762077\n",
            " 20.68060523 25.59062004 30.87902463 19.41753345 18.59475908 23.18796837\n",
            " 25.72871802 28.3234078  22.31812575 24.88336613 21.31087817 31.0527335\n",
            " 19.34403778 20.75173519 15.87445808 20.5265433  20.70117246 20.5265433\n",
            " 23.32606114 19.68233643 20.00496907 17.88381107 28.83843559 24.00526687\n",
            " 19.09817287 21.32938439 50.07163944 48.82160629 48.20203737 47.2777543\n",
            " 46.84319485 14.36205747 13.53142624 17.48924424 11.79294408 12.03751809\n",
            " 10.7690999  11.77270178 13.30284038 10.53147486 11.61391857 11.4278251\n",
            "  9.02188405  8.92022632  9.50462006  8.55668465  9.66190862 11.96240478\n",
            " 14.65412353 17.1613234  10.55147356 14.45336107 12.65116497 14.27056086\n",
            " 13.89813053 11.94012717  7.77595912  9.18480867  8.37379402 10.28701903\n",
            " 11.98974767  9.49769797  7.70573926  7.36799143 13.36327035 26.14624567\n",
            " 15.17003545 20.94325541 16.51890218 16.88756044 14.57744105 14.89023868\n",
            "  8.24976464  8.63264333  9.50804859  8.93571718  7.75831071  9.03788871\n",
            " 15.02396264 15.06486095 19.58003642 12.86473687 13.39712744  8.56134775\n",
            " 13.56904967 10.98178079 10.67788405 10.28130892 14.4042725  15.46887706\n",
            " 17.90238886 15.34185827 12.90173312 11.40186526 10.99905848  9.72482922\n",
            "  9.45412739 11.70236191  9.99097952 13.44394369 16.75333771 14.22574262\n",
            " 10.75976886 10.18568291 16.33703165 14.63372832 15.14455645 15.09377379\n",
            " 14.00999287 16.72939436 17.1613234  16.21455097 12.35874932 14.39549294\n",
            " 14.28247556 12.85554461 15.09377379 18.58227987 16.47031642 18.94780328\n",
            " 19.79664167 20.4529397  21.22275643 20.45709742 15.75204166 16.60776586\n",
            " 17.55418796 19.39206231 18.10615643 20.45030404 20.66821931 28.06922267\n",
            " 16.67357885 16.26120202 17.72975505 13.19839222 17.20168726 20.15508873\n",
            " 20.90931887 24.17717967 27.62733557 20.78673312 20.75924242 21.3133487\n",
            " 18.99382477 20.93387158 15.10676681 11.06340755 10.26917289 15.17721649\n",
            " 17.95736363 21.10085132 21.34700608 21.00568378 17.69219141 20.52223098\n",
            " 20.76838574 18.76022157 20.23462213 22.18273078 19.05073131 26.01075867\n",
            " 22.94032743 16.83667178]\n",
            "<flaml.model.LGBMEstimator object at 0x7f308d34cf10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbcg2Kxg4RA2"
      },
      "source": [
        "## Time Series Forecast"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtd-6R4o6ToZ",
        "outputId": "a855f4eb-33ea-4530-9665-6b88edd63c39"
      },
      "source": [
        "!pip install flaml[forecast]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flaml[forecast] in /usr/local/lib/python3.7/dist-packages (0.6.5)\n",
            "Requirement already satisfied: NumPy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from flaml[forecast]) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from flaml[forecast]) (1.4.1)\n",
            "Requirement already satisfied: lightgbm>=2.3.1 in /usr/local/lib/python3.7/dist-packages (from flaml[forecast]) (3.2.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from flaml[forecast]) (1.0)\n",
            "Requirement already satisfied: catboost>=0.23 in /usr/local/lib/python3.7/dist-packages (from flaml[forecast]) (1.0.0)\n",
            "Requirement already satisfied: xgboost<=1.3.3,>=0.90 in /usr/local/lib/python3.7/dist-packages (from flaml[forecast]) (0.90)\n",
            "Requirement already satisfied: prophet>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from flaml[forecast]) (1.0.1)\n",
            "Requirement already satisfied: statsmodels>=0.12.2 in /usr/local/lib/python3.7/dist-packages (from flaml[forecast]) (0.13.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml[forecast]) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml[forecast]) (1.1.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml[forecast]) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml[forecast]) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml[forecast]) (4.4.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->flaml[forecast]) (0.37.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost>=0.23->flaml[forecast]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost>=0.23->flaml[forecast]) (2018.9)\n",
            "Requirement already satisfied: cmdstanpy==0.9.68 in /usr/local/lib/python3.7/dist-packages (from prophet>=1.0.1->flaml[forecast]) (0.9.68)\n",
            "Requirement already satisfied: setuptools-git>=1.2 in /usr/local/lib/python3.7/dist-packages (from prophet>=1.0.1->flaml[forecast]) (1.2)\n",
            "Requirement already satisfied: LunarCalendar>=0.0.9 in /usr/local/lib/python3.7/dist-packages (from prophet>=1.0.1->flaml[forecast]) (0.0.9)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.7/dist-packages (from prophet>=1.0.1->flaml[forecast]) (4.62.3)\n",
            "Requirement already satisfied: Cython>=0.22 in /usr/local/lib/python3.7/dist-packages (from prophet>=1.0.1->flaml[forecast]) (0.29.24)\n",
            "Requirement already satisfied: convertdate>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from prophet>=1.0.1->flaml[forecast]) (2.3.2)\n",
            "Requirement already satisfied: holidays>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from prophet>=1.0.1->flaml[forecast]) (0.10.5.2)\n",
            "Requirement already satisfied: pystan~=2.19.1.1 in /usr/local/lib/python3.7/dist-packages (from prophet>=1.0.1->flaml[forecast]) (2.19.1.1)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.7/dist-packages (from cmdstanpy==0.9.68->prophet>=1.0.1->flaml[forecast]) (4.2.0)\n",
            "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.1.2->prophet>=1.0.1->flaml[forecast]) (0.5.11)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from holidays>=0.10.2->prophet>=1.0.1->flaml[forecast]) (0.2.1)\n",
            "Requirement already satisfied: hijri-converter in /usr/local/lib/python3.7/dist-packages (from holidays>=0.10.2->prophet>=1.0.1->flaml[forecast]) (2.2.1)\n",
            "Requirement already satisfied: ephem>=3.7.5.3 in /usr/local/lib/python3.7/dist-packages (from LunarCalendar>=0.0.9->prophet>=1.0.1->flaml[forecast]) (4.0.0.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost>=0.23->flaml[forecast]) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost>=0.23->flaml[forecast]) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost>=0.23->flaml[forecast]) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml[forecast]) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml[forecast]) (3.0.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.12.2->flaml[forecast]) (0.5.2)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost>=0.23->flaml[forecast]) (1.3.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q2uGb_62geb",
        "outputId": "e5d0fd85-5ca9-413c-bf23-ab8387e74019"
      },
      "source": [
        "import numpy as np\n",
        "from flaml import AutoML\n",
        "# Creating the data sets\n",
        "X_train = np.arange(\"2014-01\", \"2021-01\", dtype = \"datetime64[M]\")\n",
        "y_train = np.random.random(size = 72)\n",
        "# Initialize the automl instance\n",
        "automl = AutoML()\n",
        "# Model training\n",
        "automl.fit(X_train = X_train[:72],\n",
        "           y_train = y_train,\n",
        "           period = 12,\n",
        "           task = \"forecast\",\n",
        "           time_budget = 15,\n",
        "           log_file_name = \"forecast.log\",\n",
        "           )"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 10-02 07:34:50] {1432} INFO - Evaluation method: cv\n",
            "[flaml.automl: 10-02 07:34:50] {1478} INFO - Minimizing error metric: mape\n",
            "[flaml.automl: 10-02 07:34:51] {1515} INFO - List of ML learners in AutoML Run: ['prophet', 'arima', 'sarimax']\n",
            "[flaml.automl: 10-02 07:34:51] {1748} INFO - iteration 0, current learner prophet\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:prophet:n_changepoints greater than number of observations. Using 8.\n",
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:prophet:n_changepoints greater than number of observations. Using 18.\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "[flaml.automl: 10-02 07:35:01] {1866} INFO - Estimated sufficient time budget=101885s. Estimated necessary time budget=102s.\n",
            "INFO:flaml.automl:Estimated sufficient time budget=101885s. Estimated necessary time budget=102s.\n",
            "[flaml.automl: 10-02 07:35:01] {1944} INFO -  at 10.6s,\testimator prophet's best error=1.8346,\tbest estimator prophet's best error=1.8346\n",
            "INFO:flaml.automl: at 10.6s,\testimator prophet's best error=1.8346,\tbest estimator prophet's best error=1.8346\n",
            "[flaml.automl: 10-02 07:35:01] {1748} INFO - iteration 1, current learner arima\n",
            "INFO:flaml.automl:iteration 1, current learner arima\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/base/tsa_model.py:539: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency MS will be used.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/base/tsa_model.py:539: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency MS will be used.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/base/tsa_model.py:539: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency MS will be used.\n",
            "\n",
            "[flaml.automl: 10-02 07:35:02] {1944} INFO -  at 11.3s,\testimator arima's best error=2.4144,\tbest estimator prophet's best error=1.8346\n",
            "INFO:flaml.automl: at 11.3s,\testimator arima's best error=2.4144,\tbest estimator prophet's best error=1.8346\n",
            "[flaml.automl: 10-02 07:35:02] {1748} INFO - iteration 2, current learner arima\n",
            "INFO:flaml.automl:iteration 2, current learner arima\n",
            "[flaml.automl: 10-02 07:35:02] {1944} INFO -  at 12.0s,\testimator arima's best error=2.2929,\tbest estimator prophet's best error=1.8346\n",
            "INFO:flaml.automl: at 12.0s,\testimator arima's best error=2.2929,\tbest estimator prophet's best error=1.8346\n",
            "[flaml.automl: 10-02 07:35:02] {1748} INFO - iteration 3, current learner arima\n",
            "INFO:flaml.automl:iteration 3, current learner arima\n",
            "[flaml.automl: 10-02 07:35:03] {1944} INFO -  at 12.6s,\testimator arima's best error=2.2929,\tbest estimator prophet's best error=1.8346\n",
            "INFO:flaml.automl: at 12.6s,\testimator arima's best error=2.2929,\tbest estimator prophet's best error=1.8346\n",
            "[flaml.automl: 10-02 07:35:03] {1748} INFO - iteration 4, current learner arima\n",
            "INFO:flaml.automl:iteration 4, current learner arima\n",
            "[flaml.automl: 10-02 07:35:04] {1944} INFO -  at 13.7s,\testimator arima's best error=2.2929,\tbest estimator prophet's best error=1.8346\n",
            "INFO:flaml.automl: at 13.7s,\testimator arima's best error=2.2929,\tbest estimator prophet's best error=1.8346\n",
            "[flaml.automl: 10-02 07:35:04] {1748} INFO - iteration 5, current learner sarimax\n",
            "INFO:flaml.automl:iteration 5, current learner sarimax\n",
            "[flaml.automl: 10-02 07:35:04] {1944} INFO -  at 14.2s,\testimator sarimax's best error=2.4144,\tbest estimator prophet's best error=1.8346\n",
            "INFO:flaml.automl: at 14.2s,\testimator sarimax's best error=2.4144,\tbest estimator prophet's best error=1.8346\n",
            "[flaml.automl: 10-02 07:35:04] {1748} INFO - iteration 6, current learner sarimax\n",
            "INFO:flaml.automl:iteration 6, current learner sarimax\n",
            "[flaml.automl: 10-02 07:35:05] {1944} INFO -  at 14.9s,\testimator sarimax's best error=2.4144,\tbest estimator prophet's best error=1.8346\n",
            "INFO:flaml.automl: at 14.9s,\testimator sarimax's best error=2.4144,\tbest estimator prophet's best error=1.8346\n",
            "[flaml.automl: 10-02 07:35:05] {2043} INFO - selected model: <prophet.forecaster.Prophet object at 0x7f1c08aec0d0>\n",
            "INFO:flaml.automl:selected model: <prophet.forecaster.Prophet object at 0x7f1c08aec0d0>\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "[flaml.automl: 10-02 07:35:06] {2106} INFO - retrain prophet for 0.6s\n",
            "INFO:flaml.automl:retrain prophet for 0.6s\n",
            "[flaml.automl: 10-02 07:35:06] {2110} INFO - retrained model: <prophet.forecaster.Prophet object at 0x7f1bd6072910>\n",
            "INFO:flaml.automl:retrained model: <prophet.forecaster.Prophet object at 0x7f1bd6072910>\n",
            "[flaml.automl: 10-02 07:35:06] {1539} INFO - fit succeeded\n",
            "INFO:flaml.automl:fit succeeded\n",
            "[flaml.automl: 10-02 07:35:06] {1541} INFO - Time taken to find the best model: 10.575782775878906\n",
            "INFO:flaml.automl:Time taken to find the best model: 10.575782775878906\n",
            "[flaml.automl: 10-02 07:35:06] {1555} WARNING - Time taken to find the best model is 71% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
            "WARNING:flaml.automl:Time taken to find the best model is 71% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmLogluM6INt",
        "outputId": "3f61f3f5-d0f1-426c-f0d7-fe9d0a6f92e0"
      },
      "source": [
        "# Predict\n",
        "print(automl.predict(X_train[72:]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     0.585458\n",
            "1     0.695978\n",
            "2     0.529412\n",
            "3     0.763986\n",
            "4     0.914638\n",
            "5     0.439150\n",
            "6     0.731521\n",
            "7     0.669782\n",
            "8     0.718833\n",
            "9     0.277179\n",
            "10    0.559964\n",
            "11    0.413329\n",
            "Name: yhat, dtype: float64\n"
          ]
        }
      ]
    }
  ]
}